# -*- coding: utf-8 -*-
"""Attack.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MWiCZ1sRQmxgvvHAmKRpuKymFOS_5pEY
"""

!git clone https://github.com/luoluomei/Link-Stealing-Attacks-Against-Inductive-Graph-Neural-Networks-Project.git

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Link-Stealing-Attacks-Against-Inductive-Graph-Neural-Networks-Project/link_steal_pets2024

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/luoluomei/GraphGallery.git
# %cd GraphGallery

!pip install -e . --verbose
# %cd ..

!pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html

!pip install torch==2.2.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install networkx matplotlib seaborn pandas scikit-learn tqdm yacs tabulate gensim

!pip install torchdata==0.6.1

!pip install numpy==1.24.4 pandas==1.5.3 --force-reinstall

!sed -i 's/tqdm.__doc__ = tqdm_base.__doc__ + tqdm_base.__init__.__doc__/tqdm.__doc__ = (tqdm_base.__doc__ or "") + (tqdm_base.__init__.__doc__ or "")/' /content/link_steal_pets2024/GraphGallery/graphgallery/utils/tqdm.py

"""#Attack"""

import os
import subprocess
import pandas as pd
import time
import random
import shutil

def run_attack(target_dataset: str,
               shadow_datasets: list,
               shadow_models: list,
               attack_ids: list,
               props: list = [100],
               seed_num: int = 5,
               gpu: int = 0):
    """
    Run attack experiments across combinations of shadow datasets, models, and proportions.

    Parameters:
    - target_dataset: Dataset used to train the target model (e.g., "cora_ml")
    - shadow_datasets: List of datasets used for training shadow models
    - shadow_models: List of GNN model architectures (e.g., ["graphsage", "gin"])
    - attack_ids: List of attack indices (0-9)
    - props: List of proportions (e.g., [10, 50, 100])
    - seed_num: Number of random seeds
    - gpu: GPU device ID
    """
    assert all(m in ["graphsage", "gin", "gat", "gcn"] for m in shadow_models)
    assert all(a in range(10) for a in attack_ids)

    model_dir = "./data/save_model/gnn"
    os.makedirs(model_dir, exist_ok=True)
    log_path = "./output/logs/attack_performance.txt"
    result_dir = "./output/results"
    os.makedirs(result_dir, exist_ok=True)

    seeds = random.sample(range(10000), seed_num)

    print("========== Attack Configuration ==========")
    print(f"Target Dataset       : {target_dataset}")
    print(f"Shadow Datasets      : {shadow_datasets}")
    print(f"Shadow Models        : {shadow_models}")
    print(f"Attack IDs           : {attack_ids}")
    print(f"Shadow Proportions   : {props}")
    print(f"Random Seeds         : {seeds}")
    print("==========================================")

    target_model_path = os.path.join(model_dir, f"inductive_{target_dataset}_graphsage_target.pth")
    if not os.path.exists(target_model_path):
        print(f"Training target model for {target_dataset}")
        subprocess.run([
            "python", "train_gnn.py",
            "--dataset", target_dataset,
            "--model", "graphsage",
            "--mode", "target",
            "--gpu", str(gpu)
        ], check=True)
    else:
        print(f"Target model already exists: {target_model_path}")

    attack_args_map = {
        0: ["--node_topology", "0-hop"],
        1: ["--node_topology", "1-hop"],
        2: ["--node_topology", "2-hop"],
        3: ["--node_topology", "0-hop", "--plus"],
        4: ["--node_topology", "1-hop", "--plus"],
        5: ["--node_topology", "2-hop", "--plus"],
        6: ["--node_topology", "1-hop", "--plus2"],
        7: ["--node_topology", "2-hop", "--plus2"],
        8: ["--node_topology", "1-hop", "--all"],
        9: ["--node_topology", "2-hop", "--all"],
    }

    method_map = {
        0: "0-hop_posteriors",
        1: "1-hop_posteriors",
        2: "2-hop_posteriors",
        3: "0-hop_posteriors_node",
        4: "1-hop_posteriors_node",
        5: "2-hop_posteriors_node",
        6: "1-hop_posteriors_graph",
        7: "2-hop_posteriors_graph",
        8: "1-hop_posteriors_node_graph",
        9: "2-hop_posteriors_node_graph",
    }

    all_results = []

    for shadow_dataset in shadow_datasets:
        for shadow_model in shadow_models:
            for prop in props:
                # Train or confirm shadow model exists
                shadow_model_path = os.path.join(model_dir, f"inductive_{shadow_dataset}_{shadow_model}_shadow{prop}.pth")
                if not os.path.exists(shadow_model_path):
                    print(f"Training shadow model {shadow_model} for {shadow_dataset} (prop={prop})")
                    subprocess.run([
                        "python", "train_gnn.py",
                        "--dataset", shadow_dataset,
                        "--model", shadow_model,
                        "--mode", "shadow",
                        "--gpu", str(gpu),
                        "--prop", str(prop)
                    ], check=True)
                else:
                    print(f"Shadow model already exists: {shadow_model_path}")

                # Copy or symlink for compatibility
                compatible_shadow_model_path = os.path.join(model_dir, f"inductive_{target_dataset}_{shadow_model}_shadow{prop}.pth")
                if not os.path.exists(compatible_shadow_model_path):
                    shutil.copy(shadow_model_path, compatible_shadow_model_path)

                for attack_id in attack_ids:
                    print(f"\n--- Running Attack-{attack_id} ---")
                    print(f"Target Dataset       : {target_dataset}")
                    print(f"Shadow Dataset       : {shadow_dataset}")
                    print(f"Shadow Model         : {shadow_model}")
                    print(f"Shadow Prop (%)      : {prop}")
                    print(f"Attack Method        : {method_map[attack_id]}")
                    print("------------------------------------------")

                    result_path = os.path.join(result_dir, f"attack{attack_id}_summary.csv")
                    with open(log_path, "w") as f:
                        pass

                    aucs = []
                    for seed in seeds:
                        print(f"Running seed {seed}")
                        cmd = [
                            "python", "mlp_attack.py",
                            "--dataset", target_dataset,
                            "--edge_feature", "all",
                            "--target_model", "graphsage",
                            "--shadow_model", shadow_model,
                            "--lr", "0.006",
                            "--optim", "adam",
                            "--scheduler",
                            "--gpu", str(gpu),
                            "--seed", str(seed),
                            "--prop", str(prop)
                        ] + attack_args_map[attack_id]

                        try:
                            subprocess.run(cmd, check=True)
                            time.sleep(1)

                            with open(log_path, "r") as f:
                                lines = f.readlines()
                            matched = [
                                line for line in lines
                                if target_dataset in line and str(seed) in line and method_map[attack_id] in line
                            ]
                            if matched:
                                fields = matched[-1].strip().split(",")
                                test_auc = float(fields[11])
                                aucs.append(test_auc)
                                print(f"AUC = {test_auc:.4f}")
                            else:
                                print(f"No matching log for seed {seed}")
                        except subprocess.CalledProcessError:
                            print(f"Error running mlp_attack.py for seed {seed}")

                    if aucs:
                        avg_auc = round(sum(aucs) / len(aucs), 4)
                        print(f"Average AUC: {avg_auc:.4f}")
                        df = pd.DataFrame({
                            "target_dataset": [target_dataset] * len(aucs) + [target_dataset],
                            "shadow_dataset": [shadow_dataset] * len(aucs) + [shadow_dataset],
                            "shadow_model": [shadow_model] * len(aucs) + [shadow_model],
                            "attack_id": [attack_id] * len(aucs) + [attack_id],
                            "prop": [prop] * len(aucs) + [prop],
                            "seed": seeds + ["avg"],
                            "test_auc": aucs + [avg_auc]
                        })
                        df.to_csv(result_path, mode="a", index=False, header=not os.path.exists(result_path))
                        all_results.append((target_dataset, shadow_dataset, shadow_model, attack_id, prop, avg_auc))
                    else:
                        print(f"No AUCs recorded for Attack-{attack_id} with shadow {shadow_dataset} model {shadow_model} (prop {prop})")

    return all_results